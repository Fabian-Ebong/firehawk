# ~/.bashrc
# config override is altered by install scripts but can also be used to override configuration variables.

# WARNING: CHANGES TO THIS TEMPLATE MUST OCCUR AFTER A DESTROY OPERATION AND INCREMENT THE VERSION.
# WARNING: When editing your config file do not store any secrets / sensitive information here.
# Secrets should only ever be stored in the encrypted secrets file..
# This unencrypted config file is still stored in your private repository and should not be publicly available.

# CONFIG INITIALIZATION #

# Private values must be used as values only (and not in #commented lines), since it is only the values that are kept private.
# Only Commented lines and the variable names / keys are read from this private secrets/config file in your private repo to auto generate the public firehawk/config.template file when running 'source ./update_vars.sh'.

# If these steps are followed then no private values will be or should be propogated into the public repo firehawk/config.template file.
# Before making any commits of config.template to the public firehawk repo ensure there are no secrets / sensitive information contained in a commit.
# Be sure to provide any new variable keys you may end up adding with a commented out description with example dummy values above your actual private value used to assist others.

# Do not put real world sensitive information in the example comments / #commented out lines.


# BEGIN CONFIGURATION #

# defaults_config_overide_version:
# If the version of this file changes, the file will be replaced in any deployment.
defaults_config_overide_version="0.0.24"

# TF_VAR_CI_JOB_ID:
# This pipeline number is used to updat the active pipeline in the working dir when a new deployment is initialised.
TF_VAR_CI_JOB_ID=0

# TF_VAR_active_pipeline:
# This pipeline number will update when a new deployment is initialised. It is used to tag the creation of assets, and potentially define subnets ranges.
TF_VAR_active_pipeline=0

# TF_VAR_resourcetier_dev:
# Deployments between dev, and prod may use different resources.  When prod is deployed it may use a green or blue resource, allowing simultaneous deployments to operate on different resources.
TF_VAR_resourcetier_dev=grey

# TF_VAR_resourcetier_prod:
# Deployments between dev, and prod may use different resources.  When prod is deployed it may use a green or blue resource, allowing simultaneous deployments to operate on different resources.
TF_VAR_resourcetier_prod=green

# TF_VAR_vm_initialised:
# after the vms are succesfully initialised, this is set to true.  when true, vm will not be initialised again.
TF_VAR_vm_initialised=false

# TF_VAR_fast:
# this should always be false. in the defaults.  it can be changed by commits with [fast] in the comment to accelerate some steps for deployment testing.
# default: TF_VAR_fast
TF_VAR_fast=false

# allow_interrupt:
# Allows the presence of an interrupt file to force exit on current provisioning
# default: allow_interrupt=true
allow_interrupt=true

# TF_VAR_openfirehawkserver:
# The openfirehawk server vm uses this static ip assigned to the VM.  
# Before Initialisation this should be set to 'auto'.  The static ip should be updated here after initialisation automatically.
# You should also assign the current static ip in your router's settings.
# It will cause issues for your installation if the IP changes within your network and is not static.
# eg: TF_VAR_openfirehawkserver=auto
TF_VAR_openfirehawkserver=auto

# TF_VAR_deadline_proxy_root_dir:
# This is the address and port for clients to reach the Deadline RCS on the openfirehawk server in a dev environment.  After init, the default containing the var $TF_VAR_openfirehawkserver should resolve to an actual IP in this file and not be 'auto'.
# eg: TF_VAR_deadline_proxy_root_dir=$TF_VAR_openfirehawkserver:4433
TF_VAR_deadline_proxy_root_dir=$TF_VAR_openfirehawkserver:4433

# TF_VAR_vagrant_destroy_before_deploy:
# default: TF_VAR_vagrant_destroy_before_deploy=false
TF_VAR_vagrant_destroy_before_deploy=false

# TF_VAR_tf_destroy_before_deploy:
# default: TF_VAR_tf_destroy_before_deploy=false
TF_VAR_tf_destroy_before_deploy=true

# TF_VAR_destroy_after_deploy:
# In dev tests we may automatically destroy a deployment after completion.  In prod, we preserve the deployment.
# default: TF_VAR_destroy_after_deploy=false
TF_VAR_destroy_after_deploy=true

# TF_VAR_enable_vpc:
# Enable a Virtual Private Cloud.  All infrastructure is built in a VPC.  the first stage is to provision a user that has haccess to s3 bucket storage, which doesn't require a VPC.
# default: TF_VAR_enable_vpc=true
TF_VAR_enable_vpc=true

# TF_VAR_softnas_storage:
# Enable softnas storage.  Softnas is used for a centralised cloud based NFS share.
# It's licenceing cost scales with usage, and can provide RAID redundancy.
# default: TF_VAR_softnas_storage=true
TF_VAR_softnas_storage=true

# TF_VAR_aws_nodes_enabled:
# Enable cloud nodes and site NFS mounts to be mounted on remote nodes.  If you have an existing local NFS share from your own NAS, it can be provided as a remote mount over vpn for cloud based nodes.  Operating with a local NFS share is requried for PDG/TOPS to function.
# default: TF_VAR_aws_nodes_enabled=true
TF_VAR_aws_nodes_enabled=true

# TF_VAR_remote_mounts_on_local:
# Enable cloud NFS mounts to be mounted on local nodes.  After the VPN is connected, the remote SoftNAS NFS shares can be mounted on the local workstation.  This is necesary for PDG/TOPS to track completed work items, and allow remote deletion of data.
# default: TF_VAR_remote_mounts_on_local=true
TF_VAR_remote_mounts_on_local=true

# TF_VAR_provision_deadline_spot_plugin:
# If enabled, the deadline spot fleet plugin will be automatically configured.  
# Note that because we alter the mongo db, this may not be supported with future versions of deadline.  You may need to disable it and configure the plugin manually in these circumstances.
TF_VAR_provision_deadline_spot_plugin=true

# TF_VAR_install_houdini:
# default: TF_VAR_install_houdini=true
TF_VAR_install_houdini=true

# TF_VAR_houdini_test_connection:
# After a houdini install, execute a basic test job with hython.
# default: TF_VAR_houdini_test_connection=true
TF_VAR_houdini_test_connection=true

# TF_VAR_softnas_skip_update:
# default: TF_VAR_softnas_skip_update=false
TF_VAR_softnas_skip_update=false

# TF_VAR_softnas_volatile:
# If softnas volumes are volatile, they will be destroyed when infrastructure is set to sleep.
# default: TF_VAR_softnas_volatile=false
TF_VAR_softnas_volatile=false

# TF_VAR_install_deadline_db:
# default: TF_VAR_install_deadline_db=true
TF_VAR_install_deadline_db=true

# TF_VAR_install_deadline_rcs:
# default: TF_VAR_install_deadline_rcs=true
TF_VAR_install_deadline_rcs=true

# TF_VAR_install_deadline_worker:
# default: TF_VAR_install_deadline_worker=true
TF_VAR_install_deadline_worker=true

# TF_VAR_workstation_enabled:
# terraform and ansible will provision a cloud based workstation if true.
# default: TF_VAR_workstation_enabled=false
TF_VAR_workstation_enabled=false

# TF_VAR_taint_single:
# default: TF_VAR_taint_single=""
TF_VAR_taint_single=""

# TF_VAR_allow_prebuilt_softnas_ami:
# If set to false, it will replace the existing prebuilt ami.
# default: TF_VAR_allow_prebuilt_softnas_ami=true
TF_VAR_allow_prebuilt_softnas_ami=true

# TF_VAR_houdini_license_server_address:
# The ip of the houdini licence server used when in a dev or prod environment.  This will normally be the same ip server used in dev and production to not waste licences. So in a dev environment, you will probably need to reference the same houdini licence server in production.  Ideally, the houdini license server should be a seperate vm to the vagrant host for stability reasons but this is currently untested.  It is recomended that the licence server ip is the vagrant production VM until otherwise tested.  A licence server should rarely need to be touched, but updates to infrastructure could disrupt it if located on the firehawkserver vm.
# If you don't have a floating license server or intend to use one, set this to 'none'
# eg1: TF_VAR_houdini_license_server_address=192.168.29.125
# eg2: TF_VAR_houdini_license_server_address=none
TF_VAR_houdini_license_server_address=$TF_VAR_houdini_license_server_address

# TF_VAR_localnas1_private_ip:
# If using an NFS Share / NAS - The IP address of the onsite system with NFS shared volumes to mount.  This is normally your onsite NAS IP.  It is highly recommended you configure an NFS share to simplify access to small files that are ephemeral.
# If you intend to use Side FX PDG, an NFS share is currently required for ephemeral data to be shared.
# If not using an NFS share, set this to 'none'
# eg: TF_VAR_localnas1_private_ip=192.168.29.11
# eg1: TF_VAR_localnas1_private_ip=none
TF_VAR_localnas1_private_ip=$TF_VAR_localnas1_private_ip

# TF_VAR_localnas1_export_path:
# If using an NFS Share / NAS - The name of the production volume path for onsite workstations/nodes.  /prod is a relative path depending on location, so for cloud based nodes, this would usually refer to the softnas production path.  So far only /prod has been tested.
# you can use the showmount command to list the available NFS exports eg: showmount -e { My NAS IP Adress }
# If not using an NFS share, set this to 'none'
# default: TF_VAR_localnas1_export_path=/prod
# eg1: TF_VAR_localnas1_export_path=none
TF_VAR_localnas1_export_path=$TF_VAR_localnas1_export_path

# TF_VAR_localnas1_volume_name:
# If using an NFS Share / NAS - The name of the volume, usually the name of the last folder of the NFS export.
# If not using an NFS share, set this to 'none'
# default: TF_VAR_localnas1_volume_name=prod
# eg1: TF_VAR_localnas1_volume_name=none
TF_VAR_localnas1_volume_name=$TF_VAR_localnas1_volume_name

# TF_VAR_localnas1_path_abs:
# If using an NFS Share / NAS - This is the absolute path for the onsite NFS mount at all locations. For example, /mycity_prod should be the same mount path for all locations over vpn.
# If not using an NFS share, set this to 'none'
# eg: TF_VAR_localnas1_path_abs=/mycity_prod
# eg1: TF_VAR_localnas1_path_abs=none
TF_VAR_localnas1_path_abs=$TF_VAR_localnas1_path_abs

# TF_VAR_aws_key_name:
# The name of the key pair used in the dev environment. You will create a key pair to access your aws instances, listed here.
# default: TF_VAR_aws_key_name=$TF_VAR_aws_key_name
TF_VAR_aws_key_name=$TF_VAR_aws_key_name

# TF_VAR_aws_private_key_path:
# the path to the keypair from within the vagrant VM.
# default: TF_VAR_aws_private_key_path=$TF_VAR_aws_private_key_path
TF_VAR_aws_private_key_path=$TF_VAR_aws_private_key_path